{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import naive_bayes,linear_model,svm,model_selection,ensemble,tree,preprocessing\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2=pd.read_csv('C:/Users/Admin/Documents/MachineLearning/Lenddo.csv') #reading in the training set (IS fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dictionary=pd.read_csv(\"C:/Users/Admin/Documents/MachineLearning/Data Scientist - Exercises/Data_dictionary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dictionary=data_dictionary.iloc[3:,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicti=dict(zip(data_dictionary.Var,data_dictionary.Type)) #dictionary of every feature with it's data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_feature=[]  #making a list of the different types of features\n",
    "dummy=[]              \n",
    "categoricals=[]\n",
    "for k,v in dicti.items():\n",
    "    if v=='Continuous':\n",
    "        continous_feature.append(k)\n",
    "    elif v=='Dummy':\n",
    "        dummy.append(k)\n",
    "    else:\n",
    "        categoricals.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_continous=data_2[continous_feature]\n",
    "X_categoricals=data_2[categoricals]\n",
    "X_dummy=data_2[dummy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.concat([X_continous,X_categoricals,X_dummy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, data_2.iloc[:, -1], test_size=0.1, stratify=data_2.Target, random_state=4129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipe(kcount=6000, levels=[0]):\n",
    "    '''Make a pipeline of an under- and an over-sampler, that produces\n",
    "    kcount samples for each target classself.\n",
    "    levels: a list of target classes to under-sample.'''\n",
    "\n",
    "    ratio = dict(zip(levels, [kcount] * len(levels)))\n",
    "    \n",
    "\n",
    "    # down-sample majority classes to kcount\n",
    "    rus = RandomUnderSampler(random_state=4129, ratio=ratio)\n",
    "\n",
    "    # up-sample the others to kcount\n",
    "    ros = RandomOverSampler(random_state=4129)\n",
    "\n",
    "    from imblearn.pipeline import Pipeline\n",
    "    return Pipeline([('under',rus), ('over',ros)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_pipe = make_pipe(6000, levels=[0])\n",
    "x_train_r, y_train_r = samp_pipe.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:461: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of Logit Regression is:  [0.97463768 0.97454545 0.97445255]\n",
      "mean: 0.975, standard deviation: 0.000\n",
      "precision [0.         0.97575758]\n",
      "recall [0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "logit_best = linear_model.LogisticRegression(C=0.001,multi_class='multinomial',solver='newton-cg')\n",
    "logit_best.fit(x_train, y_train)                     #multinomial logistic regression with cross validation on test data##unbalanced data\n",
    "y_pred = logit_best.predict(x_test)\n",
    "labels=[1,0]\n",
    "print('accuracy of Logit Regression is: ', cross_val_score(logit_best, x_test, y_test)) \n",
    "print('mean: %.3f, standard deviation: %.3f' % (np.mean(cross_val_score(logit_best, x_test, y_test)), np.std(cross_val_score(logit_best, x_test, y_test))))\n",
    "print('precision',precision_score(y_test, y_pred, average=None, labels=labels))\n",
    "print('recall',recall_score(y_test, y_pred, average=None, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of Logit Regression on balanced data is:  [0.97463768 0.97454545 0.97445255]\n",
      "mean: 0.975, standard deviation: 0.000\n",
      "precision [0.05416667 0.98803419]\n",
      "recall [0.65       0.71801242]\n"
     ]
    }
   ],
   "source": [
    "logit_best = linear_model.LogisticRegression(C=0.001,multi_class='multinomial',solver='newton-cg')\n",
    "logit_best.fit(x_train_r, y_train_r)                     #multinomial logistic regression on balanced data with cross validation on test data\n",
    "y_pred = logit_best.predict(x_test)\n",
    "labels=[1,0]\n",
    "print('accuracy of Logit Regression on balanced data is: ', cross_val_score(logit_best, x_test, y_test)) \n",
    "print('mean: %.3f, standard deviation: %.3f' % (np.mean(cross_val_score(logit_best, x_test, y_test)), np.std(cross_val_score(logit_best, x_test, y_test))))\n",
    "print('precision',precision_score(y_test, y_pred, average=None, labels=labels))\n",
    "print('recall',recall_score(y_test, y_pred, average=None, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of RandomForest on unbalanced data is:  [0.97463768 0.97454545 0.97810219]\n",
      "mean: 0.976, standard deviation: 0.002\n",
      "precision [0.         0.97575758]\n",
      "recall [0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rforest = ensemble.RandomForestClassifier(n_estimators=50,max_depth=20,random_state = 2018)\n",
    "rforest.fit(x_train, y_train) #unbalanced data\n",
    "y_pred = rforest.predict(x_test)\n",
    "labels=[1,0]\n",
    "print('accuracy of RandomForest on unbalanced data is: ', cross_val_score(rforest, x_test, y_test)) \n",
    "print('mean: %.3f, standard deviation: %.3f' % (np.mean(cross_val_score(rforest, x_test, y_test)), np.std(cross_val_score(rforest, x_test, y_test))))\n",
    "print('precision',precision_score(y_test, y_pred, average=None, labels=labels))\n",
    "print('recall',recall_score(y_test, y_pred, average=None, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of RandomForest on rebalanced data is:  [0.97463768 0.97454545 0.97810219]\n",
      "mean: 0.976, standard deviation: 0.002\n",
      "precision [0.         0.97569866]\n",
      "recall [0.         0.99751553]\n"
     ]
    }
   ],
   "source": [
    "rforest = ensemble.RandomForestClassifier(n_estimators=50,max_depth=20,random_state = 2018)\n",
    "rforest.fit(x_train_r, y_train_r) #balanced data\n",
    "y_pred = rforest.predict(x_test)\n",
    "labels=[1,0]\n",
    "print('accuracy of RandomForest on rebalanced data is: ', cross_val_score(rforest, x_test, y_test)) \n",
    "print('mean: %.3f, standard deviation: %.3f' % (np.mean(cross_val_score(rforest, x_test, y_test)), np.std(cross_val_score(rforest, x_test, y_test))))\n",
    "print('precision',precision_score(y_test, y_pred, average=None, labels=labels))\n",
    "print('recall',recall_score(y_test, y_pred, average=None, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of Gradboost on rebalanced data is:  [0.9384058  0.96       0.96715328]\n",
      "mean: 0.955, standard deviation: 0.012\n",
      "precision [0.         0.97546012]\n",
      "recall [0.         0.98757764]\n"
     ]
    }
   ],
   "source": [
    "gboost = ensemble.GradientBoostingClassifier(n_estimators = 50, random_state = 2018,max_depth = 20)\n",
    "gboost.fit(x_train_r, y_train_r)\n",
    "y_pred = gboost.predict(x_test)\n",
    "labels=[1,0]\n",
    "print('accuracy of Gradboost on rebalanced data is: ', cross_val_score(gboost, x_test, y_test)) \n",
    "print('mean: %.3f, standard deviation: %.3f' % (np.mean(cross_val_score(gboost, x_test, y_test)), np.std(cross_val_score(gboost, x_test, y_test))))\n",
    "print('precision',precision_score(y_test, y_pred, average=None, labels=labels))\n",
    "print('recall',recall_score(y_test, y_pred, average=None, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of Gradboost on unbalanced data is:  [0.9384058  0.96       0.96715328]\n",
      "mean: 0.955, standard deviation: 0.012\n",
      "precision [0.16666667 0.97680098]\n",
      "recall [0.05       0.99378882]\n"
     ]
    }
   ],
   "source": [
    "gboost = ensemble.GradientBoostingClassifier(n_estimators = 50, random_state = 2018,max_depth = 20)\n",
    "gboost.fit(x_train, y_train)\n",
    "y_pred = gboost.predict(x_test)\n",
    "labels=[1,0]\n",
    "print('accuracy of Gradboost on unbalanced data is: ', cross_val_score(gboost, x_test, y_test)) \n",
    "print('mean: %.3f, standard deviation: %.3f' % (np.mean(cross_val_score(gboost, x_test, y_test)), np.std(cross_val_score(gboost, x_test, y_test))))\n",
    "print('precision',precision_score(y_test, y_pred, average=None, labels=labels))\n",
    "print('recall',recall_score(y_test, y_pred, average=None, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of adaboost on unbalanced data is:  [0.93478261 0.93818182 0.94160584]\n",
      "mean: 0.938, standard deviation: 0.003\n",
      "precision [0.05555556 0.97645601]\n",
      "recall [0.05       0.97888199]\n",
      "accuracy of adaboost on unbalanced data is:  [0.93478261 0.93818182 0.94160584]\n",
      "mean: 0.938, standard deviation: 0.003\n",
      "precision [0.         0.97575758]\n",
      "recall [0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "adaboost = [\n",
    "    ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth = 20), n_estimators = 50, algorithm ='SAMME', random_state = 2018),\n",
    "    ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth = 20), n_estimators = 50, algorithm ='SAMME.R', random_state = 2018)]\n",
    "for i in range(2):\n",
    "    adaboost[i].fit(x_train, y_train)\n",
    "    y_pred = adaboost[i].predict(x_test)\n",
    "    labels=[1,0]\n",
    "    print('accuracy of adaboost on unbalanced data is: ', cross_val_score(adaboost[i], x_test, y_test)) \n",
    "    print('mean: %.3f, standard deviation: %.3f' % (np.mean(cross_val_score(adaboost[i], x_test, y_test)), np.std(cross_val_score(adaboost[i], x_test, y_test))))\n",
    "    print('precision',precision_score(y_test, y_pred, average=None, labels=labels))\n",
    "    print('recall',recall_score(y_test, y_pred, average=None, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of adaboost on rebalanced data is:  [0.93478261 0.93818182 0.94160584]\n",
      "mean: 0.938, standard deviation: 0.003\n",
      "precision [0.         0.97575758]\n",
      "recall [0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of adaboost on rebalanced data is:  [0.93478261 0.93818182 0.94160584]\n",
      "mean: 0.938, standard deviation: 0.003\n",
      "precision [0.         0.97575758]\n",
      "recall [0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    adaboost[i].fit(x_train_r, y_train_r)\n",
    "    y_pred = adaboost[i].predict(x_test)\n",
    "    labels=[1,0]\n",
    "    print('accuracy of adaboost on rebalanced data is: ', cross_val_score(adaboost[i], x_test, y_test)) \n",
    "    print('mean: %.3f, standard deviation: %.3f' % (np.mean(cross_val_score(adaboost[i], x_test, y_test)), np.std(cross_val_score(adaboost[i], x_test, y_test))))\n",
    "    print('precision',precision_score(y_test, y_pred, average=None, labels=labels))\n",
    "    print('recall',recall_score(y_test, y_pred, average=None, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the given test dataset(OS)\n",
    "OS_data=pd.read_csv(\"C:/Users/Admin/Documents/MachineLearning/Data Scientist - Exercises/LENDDO_EFL_OS.csv\")\n",
    "x_test_OS=OS_data.iloc[:,1:-1]\n",
    "y_test_OS=OS_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of Best Model(Gboost) on OS data is:  [0.96105528 0.9698303  0.97106918]\n",
      "mean: 0.967, standard deviation: 0.004\n",
      "precision [0.0234375  0.98299247]\n",
      "recall [0.03658537 0.97335323]\n"
     ]
    }
   ],
   "source": [
    "#checking the best model on the provided test dataset\n",
    "y_pred_OS = gboost.predict(x_test_OS)\n",
    "labels=[1,0]\n",
    "print('accuracy of Best Model(Gboost) on OS data is: ', cross_val_score(gboost, x_test_OS, y_test_OS)) \n",
    "print('mean: %.3f, standard deviation: %.3f' % (np.mean(cross_val_score(gboost, x_test_OS, y_test_OS)), np.std(cross_val_score(gboost, x_test_OS, y_test_OS))))\n",
    "print('precision',precision_score(y_test_OS, y_pred_OS, average=None, labels=labels))\n",
    "print('recall',recall_score(y_test_OS, y_pred_OS, average=None, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "OS_data['predictions']=y_pred_OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "OS_data.to_csv('OS_data_withPredictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
